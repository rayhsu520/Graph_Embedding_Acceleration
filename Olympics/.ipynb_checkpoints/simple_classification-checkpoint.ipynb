{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import color_palette, set_style, palplot\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are in total 28 communities\n"
     ]
    }
   ],
   "source": [
    "f=open(\"communities\", \"r\")\n",
    "f1 = f.readlines()\n",
    "\n",
    "#construct community dictionary, each user -> community\n",
    "community_dict = {}\n",
    "communities = set()\n",
    "for line in f1:\n",
    "    community , ids = line.split(':')\n",
    "    communities.add(community)\n",
    "    ids = ids.strip('\\n')\n",
    "    ids = list(int(x) for x in ids.split(','))\n",
    "    for id_ in ids:\n",
    "        community_dict[id_] = community\n",
    "\n",
    "print(\"There are in total {} communities\".format(len(communities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"list.features\", \"r\")\n",
    "f1 = f.readlines()\n",
    "\n",
    "#construct list.feature dictionary list_id -> feature\n",
    "list_dict = {}\n",
    "\n",
    "for i, feature in enumerate(f1):\n",
    "    list_dict[i] = feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct a commuity graph (undirected-graph) \n",
    "user_feature_graph = nx.Graph()\n",
    "\n",
    "f = open(\"lists-to-community.txt\", \"r\")\n",
    "f1 = f.readlines()\n",
    "\n",
    "for line in f1:\n",
    "    node1, node2 = line.split(' ')\n",
    "    node1, node2 = int(node1) , int(node2)\n",
    "    user_feature_graph.add_edge(node1, node2)\n",
    "    \n",
    "#graph with community and its features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Up to here:\n",
    "\n",
    "community_dict = {community_user_id : community (str)}\n",
    "list_map = {list_feature_id : feature(str)}\n",
    "user_feature_graph is the whole graph containing all the nodes (community users and list features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part is for Bag of Words\n",
    "#Function: tags_to_BOW()\n",
    "def get_one_hot_tokens(user_feature_graph, community_dict):\n",
    "    all_ = set()\n",
    "    for node in user_feature_graph.nodes():\n",
    "        all_.add(node)\n",
    "        \n",
    "    for community in community_dict.keys():\n",
    "        if community in all_:\n",
    "            all_.remove(community)\n",
    "    \n",
    "    #all preserve the items in list_\n",
    "    all_ = list(all_)\n",
    "     \n",
    "    dictionary = {}\n",
    "\n",
    "    \n",
    "    for i, list_ in enumerate(all_):\n",
    "        dictionary[list_] = i\n",
    "\n",
    "    #this is the look up dictionaty for index that needs to add 1\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def one_hot_encoding(user_feature_graph, community_dict, one_hot_index):\n",
    "    user_to_one_hot = {}\n",
    "    \n",
    "     #this is a dictionary that tells you which index should +1\n",
    "    for user in community_dict.keys():  \n",
    "        if user in user_feature_graph.nodes():\n",
    "            one_hot_vector = np.zeros(len(one_hot_index))        \n",
    "            for neighbors in user_feature_graph.neighbors(user):\n",
    "                if neighbors in one_hot_index:\n",
    "                    one_hot_vector[one_hot_index[neighbors]] += 1\n",
    "            user_to_one_hot[user] = one_hot_vector\n",
    "    \n",
    "    return user_to_one_hot\n",
    "\n",
    "\n",
    "def community_to_one_hot(user_feature_graph, community_dict):\n",
    "    one_hot_index = get_one_hot_tokens(user_feature_graph, community_dict)\n",
    "    \n",
    "    #Make the tags in the format of BOW\n",
    "    community_one_hot = one_hot_encoding(user_feature_graph, community_dict, one_hot_index)\n",
    "\n",
    "    return community_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5620915032679739\n",
      "0.5593443857729572\n",
      "0.5620915032679739\n",
      "0.954248366013072\n",
      "0.9440031678510941\n",
      "0.954248366013072\n"
     ]
    }
   ],
   "source": [
    "#MAIN\n",
    "\n",
    "\n",
    "community_one_hot = community_to_one_hot(user_feature_graph, community_dict)\n",
    "\n",
    "#X= one-hot, Y = community_according_to_label\n",
    "\n",
    "label = {\"archery\":0, \"athletics\":1, \"badminton\":2, \"basketball\":3, \"beach-volleyball\":4,\n",
    "         \"boxing\":5, \"canoeing\":6, \"cycling\":7, \"diving\":8, \"equestrianism\":9,\n",
    "         \"fencing\":10, \"gymnastics\":11, \"handball\":12, \"hockey\":13, \"judo\":14,\n",
    "         \"pentathlon\":15, \"rowing\":16, \"sailing\":17, \"shooting\":18, \"swimming\":19,\n",
    "         \"swimming-sync\":20, \"tabletennis\":21, \"taekwondo\":22, \"tennis\":23, \"triathlon\":24,\n",
    "         \"waterpolo\":25, \"weightlifting\":26, \"wrestling\":27}\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for user in community_dict.keys():\n",
    "    if user in user_feature_graph.nodes():\n",
    "        X.append(community_one_hot[user])\n",
    "        y.append(label[community_dict[user]])\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "#train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "#K-NN\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "print(knn.score(X_test, y_test))\n",
    "print(f1_score(y_test, knn.predict(X_test), average='macro'))\n",
    "print(f1_score(y_test, knn.predict(X_test), average='micro'))\n",
    "\n",
    "\n",
    "#random-forest\n",
    "rdf = RandomForestClassifier()\n",
    "rdf.fit(X_train, y_train)\n",
    "print(rdf.score(X_test, y_test))\n",
    "print(f1_score(y_test, rdf.predict(X_test), average='macro'))\n",
    "print(f1_score(y_test, rdf.predict(X_test), average='micro'))\n",
    "\n",
    "#anything-else\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
