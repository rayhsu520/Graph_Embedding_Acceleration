{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import color_palette, set_style, palplot\n",
    "import random\n",
    "from ge import DeepWalk, LINE, Node2Vec, SDNE, Struc2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are in total 28 communities\n"
     ]
    }
   ],
   "source": [
    "f=open(\"communities\", \"r\")\n",
    "f1 = f.readlines()\n",
    "\n",
    "#construct community dictionary, each user -> community\n",
    "community_dict = {}\n",
    "communities = set()\n",
    "for line in f1:\n",
    "    community , ids = line.split(':')\n",
    "    communities.add(community)\n",
    "    ids = ids.strip('\\n')\n",
    "    ids = list(int(x) for x in ids.split(','))\n",
    "    for id_ in ids:\n",
    "        community_dict[id_] = community\n",
    "\n",
    "print(\"There are in total {} communities\".format(len(communities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"list.features\", \"r\")\n",
    "f1 = f.readlines()\n",
    "\n",
    "#construct list.feature dictionary list_id -> feature\n",
    "list_dict = {}\n",
    "\n",
    "for i, feature in enumerate(f1):\n",
    "    list_dict[i] = feature"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Up to here:\n",
    "\n",
    "community_dict = {community_user_id : community (str)}\n",
    "list_map = {list_feature_id : feature(str)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_edgelist('lists-to-community.txt',create_using=nx.Graph(),nodetype=None,data=[('weight',int)])#read graph\n",
    "for u,v,d in G.edges(data=True):\n",
    "    d['weight'] = 1\n",
    "#print(G.edges.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n",
      "The average training time is 3.115568161010742 secs for walk length as 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n",
      "The average training time is 7.139678001403809 secs for walk length as 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n",
      "The average training time is 8.836431741714478 secs for walk length as 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n",
      "The average training time is 17.935011863708496 secs for walk length as 20\n"
     ]
    }
   ],
   "source": [
    "#The embeddings are dictionary nodeid -> numpy arrays (embeddings)\n",
    "\n",
    "label = {\"archery\":0, \"athletics\":1, \"badminton\":2, \"basketball\":3, \"beach-volleyball\":4,\n",
    "         \"boxing\":5, \"canoeing\":6, \"cycling\":7, \"diving\":8, \"equestrianism\":9,\n",
    "         \"fencing\":10, \"gymnastics\":11, \"handball\":12, \"hockey\":13, \"judo\":14,\n",
    "         \"pentathlon\":15, \"rowing\":16, \"sailing\":17, \"shooting\":18, \"swimming\":19,\n",
    "         \"swimming-sync\":20, \"tabletennis\":21, \"taekwondo\":22, \"tennis\":23, \"triathlon\":24,\n",
    "         \"waterpolo\":25, \"weightlifting\":26, \"wrestling\":27}\n",
    "\n",
    "\n",
    "#Deepwalk\n",
    "exp_time = 1\n",
    "\n",
    "file_fscore = \"Olympics_report.csv\"\n",
    "F_score = open(file_fscore, \"w\")\n",
    "F_score.write('Walk_length, testing_percentage, Micro-f1, Macro-f1\\n')\n",
    "\n",
    "time_dict = collections.defaultdict(float)\n",
    "for walk_len in [3, 8, 10, 20]:\n",
    "    Micro_dict = collections.defaultdict(float)\n",
    "    Macro_dict = collections.defaultdict(float)\n",
    "    for i in range(exp_time):\n",
    "        start = time.time()\n",
    "        DeepWalk_model = DeepWalk(G, walk_length=walk_len,num_walks=10,workers=1)#init model\n",
    "        DeepWalk_model.train(embed_size = 128, window_size=2,iter=3)# train model\n",
    "        time_dict[walk_len]+= (time.time()-start)\n",
    "        DeepWalk_embeddings = DeepWalk_model.get_embeddings()# get embedding vectors\n",
    "\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for user in community_dict.keys():\n",
    "            try:\n",
    "                X.append(DeepWalk_embeddings[str(user)])\n",
    "                y.append(label[community_dict[user]])\n",
    "            except:\n",
    "                continue\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        #train_test_split\n",
    "        for training_percentage in np.linspace(0.1,0.9,9):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= (1-training_percentage))\n",
    "            clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "#             Micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "#             Macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            Micro_dict[training_percentage] += f1_score(y_test, y_pred, average='micro')\n",
    "            Macro_dict[training_percentage] += f1_score(y_test, y_pred, average='macro')\n",
    "    for training_percentage in np.linspace(0.1,0.9,9):\n",
    "        Micro_dict[training_percentage] /= exp_time\n",
    "        Macro_dict[training_percentage] /= exp_time\n",
    "\n",
    "        record = \"{}, {}, {}, {}\\n\".format(walk_len, training_percentage,round(Micro_dict[training_percentage],3),\n",
    "                                           round(Macro_dict[training_percentage],3))\n",
    "\n",
    "        file_fscore = \"Olympics_report.csv\"\n",
    "        F_score = open(file_fscore, \"a\")\n",
    "        F_score.write(record)\n",
    "        \n",
    "    print(\"The average training time is {} secs for walk length as {}\".format(time_dict[walk_len]/exp_time, walk_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINE\n",
    "# LINE_model = LINE(G,embedding_size=128,order='second') #init model,order can be ['first','second','all']\n",
    "# LINE_model.train(batch_size=1024,epochs=50,verbose=2)# train model\n",
    "# LINE_embeddings = LINE_model.get_embeddings()# get embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node2Vec\n",
    "\n",
    "# Node2Vec_model = Node2Vec(G, walk_length = 3, num_walks = 10,p = 0.25, q = 4, workers = 1)#init model\n",
    "# Node2Vec_model.train(window_size = 5, iter = 3)# train model\n",
    "# Node2Vec_embeddings = Node2Vec_model.get_embeddings()# get embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SDNE\n",
    "\n",
    "# SDNE_model = SDNE(G,hidden_size=[256,128]) #init model\n",
    "# SDNE_model.train(batch_size=3000,epochs=40,verbose=2)# train model\n",
    "# SDNE_embeddings = SDNE_model.get_embeddings()# get embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Struc2Vec\n",
    "\n",
    "# Struc2Vec_model = model = Struc2Vec(G, 10, 80, workers=4, verbose=40, ) #init model\n",
    "# Struc2Vec_model.train(window_size = 5, iter = 3)# train model\n",
    "# Struc2Vec_embeddings = Struc2Vec_model.get_embeddings()# get embedding vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning embedding vectors...\n",
      "Learning embedding vectors done!\n"
     ]
    }
   ],
   "source": [
    "time_dict = collections.defaultdict(float)\n",
    "exp_time = 2\n",
    "file_score = \"time.csv\"\n",
    "time_score = open(file_score, \"w\")\n",
    "time_score.write('Walk_length, Training_time\\n')\n",
    "for walk_len in [1,5,25,125]:\n",
    "    for i in range(exp_time):\n",
    "        DeepWalk_model = DeepWalk(G, walk_length=walk_len,num_walks=10,workers=1)#init model\n",
    "        start = time.time()\n",
    "        DeepWalk_model.train(embed_size = 128, window_size=2,iter=3)# train model\n",
    "        time_dict[walk_len]+= (time.time()-start)\n",
    "        DeepWalk_embeddings = DeepWalk_model.get_embeddings()# get embedding vectors\n",
    "\n",
    "    time_score.write(\"{}, {}\\n\".format(walk_len, time_dict[walk_len]/exp_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
